---
title: "Stereotyping"
output: 
    html_document:
      code_download: TRUE
      toc: TRUE
      toc_float:
        collapsed: FALSE
      toc_depth: 1
      code_folding: hide
editor_options: 
  chunk_output_type: console
---


```{r setup data import and cleaning, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE, include = FALSE}
# Cleaning
## import data

#install.packages("rio")
#install.packages("here")
#install.packages("tidyverse")
#install.packages("magrittr")
#install.packages("janitor")
#install.packages("lme4")
#install.packages("emmeans")
#install.packages("metafor")
#install.packages("Cairo")
#install.packages("tinytex")
#install.packages("compute.es")
#install.packages("multcomp")
#install.packages("car")
#install.packages("emmeans")
#install.packages("metapower")
library(rio)
library(here)
library(magrittr)
library(janitor)
library(lme4)
library(emmeans)
library(Cairo)
library(tinytex)
library(metafor)
library(compute.es)
library(multcomp)
library(car)
library(tidyverse)
library(emmeans)
library(metapower)

# Setting global chunk options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)

# Windows messes up my plots, these lines of code make them clearer
knitr::opts_knit$set(dev.args = list(type = "cairo"))

trace(grDevices:::png, quote({
  if (missing(type) && missing(antialias)) {
    type <- "cairo-png"
    antialias <- "subpixel"
  }
}), print = FALSE)

options(scipen=999)

# importing data
converted_data <- import("converted_data.csv") 

# Importing functions I wrote from R document in this project
source("functions/meta_functions.R")

# data prep
## Using function I wrote to clean data
meta_data <- meta_clean_func(converted_data)
```

# Descriptives {.tabset .tabset-fade .tabset-pills}

```{r stereo model data prep, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
#collapsing across conditions for data-prep
## creating dataset collapsing across "day in the life" versus "other control"
meta_stereo1 <- meta_data %>% 
  mutate(pt_comparison = fct_collapse(pt_comparison, 
                                      self_v_control = c("1", "2"),
                                      self_v_objective = c("3"),
                                      other_v_control = c( "5", "6"),
                                      other_v_objective = c("7"))) %>% 
  filter(pt_comparison == "self_v_control" | pt_comparison == "self_v_objective" | 
           pt_comparison == "other_v_control" | pt_comparison == "other_v_objective") %>% 
  mutate(pt_comparison = as.factor(droplevels(pt_comparison))) %>% 
  mutate(pt_comparison = fct_relevel(pt_comparison, 
                                     "self_v_objective",
                                     "self_v_control",
                                     "other_v_objective",
                                     "other_v_control"))
meta_stereo1 %<>% 
  filter(outcome_type == "1")

meta_stereo1$outcome_scale_group <- droplevels(meta_stereo1$outcome_scale_group)

## creating dataset collapsing across imagine-self and other to examine "day in the life" versus "other control"
meta_stereo2 <- meta_data %>% 
  mutate(pt_comparison = fct_collapse(pt_comparison,
                                      pt_v_day_control = c("1", "5"),
                                      pt_v_other_control = c("2", "6"),
                                      pt_v_objective = c("3", "7"))) %>% 
  filter(pt_comparison == "pt_v_day_control" |
           pt_comparison == "pt_v_other_control" |
           pt_comparison == "pt_v_objective") %>% 
  mutate(pt_comparison = as.factor(droplevels(pt_comparison)))

meta_stereo2 %<>% 
  filter(outcome_type == "1")

meta_stereo2$outcome_scale_group <- droplevels(meta_stereo2$outcome_scale_group)
```

## Unique effect sizes

```{r stereo effect size num}
meta_stereo1 %>% 
  count()
```

## Number of unique samples

```{r}
meta_stereo1 %>% 
  dplyr::select(sample_number_total) %>% 
  unique() %>% 
  count()
```

## Average sample size per cell

**To be used in power analysis**

```{r n per cell stereo}
meta_stereo1 %>% 
  dplyr::select(n_pt, n_comparison) %>% 
  unique() %>% 
  summarise(mean(n_pt),
            mean(n_comparison))
```

# Stereotyping Results: Imagine-self vs imagine-other Model {.tabset .tabset-fade .tabset-pills}

## Results:

**Contrasts:**

```{r stereo1 conrasts}
contrasts(meta_stereo1$pt_comparison) 
```

**Results:**

```{r stereo model imagine self vs other}
stereo_meta1 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num, 
                                    ~ 1 | outcome_scale_group), data = meta_stereo1)

stereo_meta1
```

The intercept is not significantly different from zero, nor do any effects differ from it.

## Marginal main effects

```{r emmeans stereo1}
qdrq_stereo1 <- qdrg(object = stereo_meta1, data = meta_stereo1)

emmeans_stereo1 <- summary(emmeans(qdrq_stereo1, "pt_comparison"))
emmeans_stereo1

emmeans_stereo1 %>% ggplot(aes(x = pt_comparison, y = emmean)) + 
  geom_col() +
  theme_minimal() +
  labs(title = "Imagine-self vs other & objective vs control instructions in stereotyping only",
       subtitle = "Lower effect sizes = more prejudice reduction (better)",
       x = "Perpsective taking comparison",
       y = "Average effect size (d unbiased)") +
  scale_x_discrete(labels = c('Self vs Objective','Self vs Control',
                              'Other vs Objective', 'Other vs Control'))
```

None of the marginal main effects differ from zero. There is an interesting pattern in that self or other vs objective lead to higher effect sizes (less stereotype prejudice reduction). However, with nothing differing from zero, this does not mean anything statistically.

## Checking if model is over-parametized

```{r check if model is over parametized, eval = FALSE}
# Checking if model is over-parametized
# code is very slow, so will not include in markdown
par(mfrow=c(2,2))
profile(stereo_meta1)

# This model is slightly over-parametized, as demonstrated by the single missing value in the plot for sigma 4. This missing value indicates the model did not converge at this location. Previously, when the structure of the MLM meta-analysis included modeling effect-size nested twice within both crossed structures, there were significant flat portions for the plots of sigma 4 and what would have been sigma 6 (effect size nested within outcome_scale_group). That model was more overparametized. We may want to consider collapsing across our within-study variance variables to see if that helps with overparametization, or decide to remove the one that accounts for little (or possibly no) variance

# http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011#a_common_mistake_in_the_three-level_model
```

## Heterogeneity

### I2 overall

```{r overall I2 stereo 1}
get_I2_overall(meta_stereo1, stereo_meta1)
```

Again, very high.

### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r levels I2 stereo 1}
get_I2_levels(stereo_meta1)
```

Most of the heterogeneity is explained by between-studies variance, with about 12% also explained by between-conditions (within-study) variance. This differed from the heterogeneity pattern found in the overall interaction model.

## Post-hoc power

* k = 138 is the number of effect sizes
* Sample size is the average found earlier to the nearest number the r function would take
* The effect sizes are from the marginal effect size outcomes

```{r power stereo 1}
subgroup_power(n_groups = 4, 
               effect_sizes = c(.08, -.08, .02, -.11), 
               sample_size = 100,
               k = 138,
               es_type = "d")
```

# Moderator Results: Imagine self vs other model {.tabset .tabset-fade .tabset-pills}

## Scales of measurement

```{r stereo 1 mod1}
meta_stereo1 %>% 
  group_by(pt_comparison, outcome_scale_group) %>% 
  count() %>% 
  filter(n <2) 

#getting rid of cells with only 1
meta_stereo1_mod1_dat <- meta_stereo1 %>% 
  filter(!c(pt_comparison == "self_v_objective" & outcome_scale_group == "1" |
           pt_comparison == "self_v_control" & outcome_scale_group == "1"))

stereo_meta1_mod1 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*outcome_scale_group,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num), data = meta_stereo1_mod1_dat)

stereo_meta1_mod1

```

I dropped cells with only 1 study and rma.mv dropped cells with 0. Nothing is significant from one another, and the intercept is not significantly different from 0. Any model with redudancies (0's in cells) cannot be modeled using emmeans to get marginal means.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo1 mod scales}
get_I2_overall(meta_stereo1_mod1_dat, stereo_meta1_mod1)
```

Still very high, but slightly lower than without the moderater.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stere1 mod scales}
get_I2_var_levels(meta_stereo1_mod1_dat, stereo_meta1_mod1)
```

Without the crossed variance structure (because it is a moderator), more of that variance shifted to the between-conditions level. Most of the variance is still represented by the between-studies level.

## Target moderator - information amount

```{r stereo 1 mod2}
stereo_meta1_mod2 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*target_information,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group/effect_size_num), data = meta_stereo1)

stereo_meta1_mod2
```

Nothing is significant.

```{r emmeans stereo1 mod2 }
qdrq_stereo1_mod2 <- qdrg(object = stereo_meta1_mod2, data = meta_stereo1)

emmeans_stereo1_mod2 <- summary(emmeans(qdrq_stereo1_mod2, "pt_comparison", "target_information"))
emmeans_stereo1_mod2
```

None of the effect sizes significantly differ from 0 when looking at the marginal main effects when broken down by target information.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo1 mod2}
get_I2_overall(meta_stereo1, stereo_meta1_mod2)
```

Compared to the original stereotyping model this is moderator, the overall heterogeneity is slightly higher.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stere1 mod2}
get_I2_levels(stereo_meta1_mod2)
```

Most of the variance is between-studies, with a somewhat significant amount explained by between-outcome (within-study) variance.

## Target moderator - target out-group

```{r stereo 1 mod3}
stereo1_group_data <- meta_stereo1 %>% 
  select(dunb, var_dunb, pt_comparison, target_out_minor, sample_number_total,
         outcomes_within_sample_var, conditions_within_sample_var, outcome_scale_group, effect_size_num) %>% 
  na.omit()

stereo_meta1_mod3 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*target_out_minor,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group/effect_size_num), data = stereo1_group_data)

stereo_meta1_mod3
```

Nothing is significant.

```{r emmeans stereo1 mod3}
qdrq_stereo1_mod3 <- qdrg(object = stereo_meta1_mod3, data = stereo1_group_data)

emmeans_stereo1_mod3 <- summary(emmeans(qdrq_stereo1_mod3, "pt_comparison", "target_out_minor"))
emmeans_stereo1_mod3
```

None of the effect sizes significantly differ from 0 when looking at the marginal main effects when broken down by by target group.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo1 mod3}
get_I2_overall(stereo1_group_data, stereo_meta1_mod3)
```

About the same as the original model without moderators.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stere1 mod3}
get_I2_levels(stereo_meta1_mod3)
```

Most of the variance is explained by between-studies or between-conditions (within-study) variance. Interestingly, there is 0% variance explained by between-outcomes variance.

## Sample size

```{r stereo 1 mod4}
stereo_meta1_mod4 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*n_overall,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group/effect_size_num), data = meta_stereo1)

stereo_meta1_mod4
```

Sample size does not interact with pt comparison.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo1 mod4}
get_I2_overall(meta_stereo1, stereo_meta1_mod4)
```

Heterogeneity is about the same as the model without moderators.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stere1 mod4}
get_I2_levels(stereo_meta1_mod4)
```

Most variance is explained by between-studies variance, followed by between-outcomes (within-study) variance.

# Stereotyping Results: Model comparing "day in the life," other control, and objective comparisons {.tabset .tabset-fade .tabset-pills}

## Results

**Contrasts:**

```{r stereo2 contrasts}
contrasts(meta_stereo2$pt_comparison) 
```

**Results:**

```{r stereo model day in the life vs other control vs objective}
# OVerall model across outcome type
stereo_meta2 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num, 
                                    ~ 1 | outcome_scale_group/effect_size_num), data = meta_stereo2)

stereo_meta2
```

Pairwise comparisons to compare:

* pt_v_objective to pt_v_other control

```{r pairwise comparisons stereo 2}
anova(stereo_meta2, btt=2:3)
```

They do not significantly differ.

## Marginal main effects:

```{r emmeans stereo2}
qdrq_stereo2 <- qdrg(object = stereo_meta2, data = meta_stereo2)

emmeans_stereo2 <- summary(emmeans(qdrq_stereo2, "pt_comparison"))
emmeans_stereo2

emmeans_stereo2 %>% ggplot(aes(x = pt_comparison, y = emmean)) + 
  geom_col() +
  theme_minimal() +
  labs(title = "'Day in the life' control vs other comparison conditions in stereotyping only",
       subtitle = "Lower effect sizes = more prejudice reduction (better)",
       x = "Perpsective taking comparison",
       y = "Average effect size (d unbiased)") +
  scale_x_discrete(labels = c('Vs `Day in the life` control','Vs other control',
                              'Vs objective'))
```

The marginal main effects do not differ from 0.

## Heterogeneity

### Overall I2

```{r overall I2 stereo 2}
get_I2_overall(meta_stereo2, stereo_meta2)
```

Heterogeneity is high.

### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r levels I2 stereo 2}
get_I2_levels(stereo_meta2)
```

Most hetereogeneity is explained by between-study variance, followed by between-condition variance.

## Post-hoc power

* k = 138 is the number of effect sizes
* Sample size is the average found earlier to the nearest number the r function would take
* The effect sizes are from the marginal effect size outcomes

```{r power stereo 2}
subgroup_power(n_groups = 3, 
               effect_sizes = c(.00, -.03, .10), 
               sample_size = 99,
               k = 138,
               es_type = "d")
```

# Moderator Results: Model comparing "day in the life," other control, and objective comparisons {.tabset .tabset-fade .tabset-pills}

## Scales of measurement

```{r stereo 2 mod1}
stereo_meta2_mod1 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*outcome_scale_group,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num), data = meta_stereo2)

stereo_meta2_mod1
```

Nothing is significant from one another, and the intercept is not significantly different from 0. Outcome scale group 5 (Essay stereotypicality) is marginally different from the intercept outcome scale group 1 (IAT). Rma.mv dropped cells with 0 due to redundancies, and therefore cannot be modeled in emmeans.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo2 mod scales}
get_I2_overall(meta_stereo2, stereo_meta2_mod1)
```

About the same as the model without moderators.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stereo2 mod scales}
get_I2_levels(stereo_meta2_mod1)
```

Most hetereogeneity is explained by between-studies variance, followed by between-outcomes (within-study) variance.

## Target moderator - information amount

```{r stereo 2 mod2}
stereo_meta2_mod2 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*target_information,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group/effect_size_num), data = meta_stereo2)

stereo_meta2_mod2
```

Pt v other control with medium target information is marginally different from the intercept (p vs "day  in the life" control with impoverished information). Nothing else is significant from the intercept, nor is the intercept significant.

### Marginal main effect

```{r emmeans stereo2 mod2 }
qdrq_stereo2_mod2 <- qdrg(object = stereo_meta2_mod2, data = meta_stereo2)

emmeans_stereo2_mod2 <- summary(emmeans(qdrq_stereo2_mod2, "pt_comparison", "target_information"))
emmeans_stereo2_mod2
```

None of the effect sizes significantly differ from 0 when looking at the marginal means when broken down by target information.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo2 mod2}
get_I2_overall(meta_stereo2, stereo_meta2_mod2)
```

Slightly higher than the original model without moderators.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stereo2 mod2}
get_I2_levels(stereo_meta2_mod2)
```

Most hetereogeneity is explained by between-studies variance, followed by between-outcomes (within-study) variance.

## Target moderator - target out-group

```{r stereo 2 mod3}
stereo2_group_data <- meta_stereo2 %>% 
  select(dunb, var_dunb, pt_comparison, target_out_minor, sample_number_total,
         outcomes_within_sample_var, conditions_within_sample_var, outcome_scale_group, effect_size_num) %>% 
  na.omit()

stereo_meta2_mod3 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*target_out_minor,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group/effect_size_num), data = stereo2_group_data)

stereo_meta2_mod3
```

The intercept (pt v day in the life control with out-group target) is significantly different from 0. Pt v control is marginally different from the intercept, and pt v objective is significantly different from the intercept. The simple main effect of target out-group group is significant: in the "day in the life" control, there are higher positive effect sizes (less prejudice reduction) for non-out-group/minority targets than out-group/minority targets. The interactions are also significant, indicating there are differences between the differences for both pt_v_control with a non-out-group minority target and p_v_objective with a non-out-group/minority target in comparison to the intercept. The marginal main effects will show the estimates of each of these comparisons better, as well as if they differ from 0.

### Marginal main effects

```{r emmeans stereo2 mod3}
qdrq_stereo2_mod3 <- qdrg(object = stereo_meta2_mod3, data = stereo2_group_data)

emmeans_stereo2_mod3 <- summary(emmeans(qdrq_stereo2_mod3, "pt_comparison", "target_out_minor"))
emmeans_stereo2_mod3

outgroup_label <- c("1" = "Outgroup/Minority", "2" = "Non-Outgroup/Minority")

emmeans_stereo2_mod3 %>% ggplot(aes(x = pt_comparison, y = emmean)) + 
  facet_grid(cols = vars(target_out_minor),
             labeller = labeller(target_out_minor = outgroup_label)) +
  geom_col() +
  theme_minimal() +
  labs(title = "'Day in the life' control vs other comparison conditions in stereotyping only",
       subtitle = "Lower effect sizes = more prejudice reduction (better)",
       x = "Perpsective taking comparison",
       y = "Average effect size (d unbiased)") +
  scale_x_discrete(labels = c('Vs `Day in the life`','Vs other control',
                              'Vs objective'))
```

### Heterogeneity

#### I2 overall

```{r I2 overall stereo2 mod3}
get_I2_overall(stereo2_group_data, stereo_meta2_mod3)
```

About the same as the model without moderaters.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stere2 mod3}
get_I2_levels(stereo_meta2_mod3)
```

Most heterogeneity explained by between-studies variance, or between-conditions variance.

## Sample size

```{r stereo 2 mod4}
stereo_meta2_mod4 <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison*n_overall,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group/effect_size_num), data = meta_stereo2)

stereo_meta2_mod4
```

Sample size does not interact with pt comparison. None of the effects are significant.

### Heterogeneity

#### I2 overall

```{r I2 overall stereo2 mod4}
get_I2_overall(meta_stereo2, stereo_meta2_mod4)
```

Heterogeneity is the same as in the model without moderators.

#### I2 for levels of variance

*Left value corresponds to top sigma in Variance components output in model results (Sample_number_total). Right-most value corresponds to bottom sigma (Outcome_scale group).*

```{r I2 var levels stere2 mod4}
get_I2_levels(stereo_meta2_mod4)
```

Heterogeneity is explained by between-studies variance the most, followed almost equally by between-conditions and between-outcomes variance.

# Publication Bias - Egger's Test {.tabset .tabset-fade .tabset-pills}

```{r}
# Getting modified covariate that removes artifactual correlation between SMD ES and its related variance
eggers_data_stereo <- meta_stereo1 %>% # Does not matter which dataset we use bc the differences between are with moderators and we are looking specifically at effect sizes and SE (or modified covariate) without moderators 
    mutate(Va = 4/(n_overall), 
         sda = sqrt(Va),
         sdi = sqrt(var_dunb))

# Adapted from Rodgers & Putjevosky (2019) https://osf.io/7ak2m/?view_only=e74f9ddad3834e0e8c0bae9ef6b0441c

mlma_egg_mod_sda_stereo <- rma.mv(dunb ~ 1 + sda, 
                           V = var_dunb, 
                           random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group), 
                           data = eggers_data_stereo, test = "t")


mlma_egg_mod_se_stereo <- rma.mv(dunb ~ 1 + sdi, 
                           V = var_dunb, 
                           random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num,
                                    ~ 1 | outcome_scale_group), 
                           data = eggers_data_stereo, test = "t")


mlma_results_sda_stereo <- with(mlma_egg_mod_sda_stereo, 
                                 data.frame(Egger_test = "Modified Covariate",
                                                      beta = b[2], 
                                                      se = se[2], 
                                                      p_val = pt(zval[2], dfs, lower.tail = FALSE))) #this is the t-value

mlma_results_se_stereo <- with(mlma_egg_mod_se_stereo, 
                                data.frame(Egger_test = "Standard Error",
                                                    beta = b[2], 
                                                    se = se[2], 
                                                    p_val = pt(zval[2], dfs, lower.tail = FALSE))) #this is the t-value

egger_stereo_results <- rbind(mlma_results_sda_stereo, mlma_results_se_stereo)
egger_stereo_results
```

# Checking sub-sample heterogeneity 

## Number of effect sizes in each scale of measurement

```{r}
meta_stereo1 %>% 
  mutate(outcome_scale_group = dplyr::recode(outcome_scale_group,
                                                 `1` = "implicit stereo RT",
                                                 `2` = "implicit stereo other",
                                                 `3` = "stereo trait attribution or ratings",
                                                 `4` = "agreement w stereotypes toward group",
                                                 `5` = "essay stereo",
                                                 `6` = "attitudes toward target")) %>% 
  count(outcome_scale_group) 
```

We will use agreement with stereotypes/prejudice toward group, as it has the most effect sizes.

### With each comparison, the cells become small though

```{r}
meta_stereo1 %>% 
  filter(outcome_scale_group == 4) %>% 
  group_by(pt_comparison) %>% 
  count()
```

## Meta sub-example w/ pt as moderator

```{r}
heterotest1_stereo <- meta_stereo1 %>% 
  filter(outcome_scale_group == 4)

# Dropped crossed factor because we filtered down to one outcome
stereo_meta1_heterotest <- rma.mv(dunb, 
                      var_dunb, 
                      mods = ~ pt_comparison,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/conditions_within_sample_var/effect_size_num), data = heterotest1_stereo)

stereo_meta1_heterotest 
```

### Heterogeneity

#### Overall

```{r}
get_I2_overall(heterotest1_stereo, stereo_meta1_heterotest)
```

#### Levels

```{r}
get_I2_levels(stereo_meta1_heterotest)
```

### Post-hoc power

```{r n per cell stereo hetero test 1}
heterotest1_stereo %>% 
  dplyr::select(n_pt, n_comparison) %>% 
  unique() %>% 
  summarise(mean(n_pt),
            mean(n_comparison))
```

**Rounded up on sample size because "sample size must be a multiple of n_groups."**

```{r power stereo hetero test 1}
subgroup_power(n_groups = 4, 
               effect_sizes = c(.12, -.08, -.34, -.22), 
               sample_size = 68,
               k = 39,
               es_type = "d")
```

## Meta sub-example w/ one pt instruction

```{r}
heterotest2_stereo <- heterotest1_stereo %>% 
  filter(pt_comparison == "self_v_objective")

# Dropped crossed factor and conditions because we filtered down to one outcome and instruction type
stereo_meta1_heterotest2 <- rma.mv(dunb, 
                      var_dunb,
                      random = list(~ 1 | sample_number_total/outcomes_within_sample_var/effect_size_num), data = heterotest2_stereo)

stereo_meta1_heterotest2 
```

### Heterogeneity

#### Overall

```{r}
get_I2_overall(heterotest2_stereo, stereo_meta1_heterotest2)
```

#### Levels

```{r}
get_I2_levels(stereo_meta1_heterotest2)
```

Heterogeneity goes back up... We did not remove "outcomes_within_sample_var" because some studies did include two multiple related measures (agreement with prejudice and stereotyping). Apparently there is some heterogeneity between these measures.

### Post-hoc power


```{r n per cell stereo hetero test 2}
heterotest2_stereo %>% 
  dplyr::select(n_pt, n_comparison) %>% 
  unique() %>% 
  summarise(mean(n_pt),
            mean(n_comparison))
```

Code below did not work. However, author had a shiny app using same code, so using that with the below data we found that power at approximately 85% heterogeneity is incredibly low: 0.15.

Shiny app: https://jason-griffin.shinyapps.io/shiny_metapower/

```{r power stereo hetero test 2, eval = FALSE}
mpower(effect_size = .11, study_size = 181, k = 16, i2 = .86, es_type= "d", 
       test_type = "two-tailed", p = 0.05)
```

